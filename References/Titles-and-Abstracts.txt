References with Abstracts for Wavelet Project for GPU Technology Conference

1. Y. Ji, S. Lakshminarasimhan, N. Shah, et al., “S-preconditioner for multi-fold data reduction with guaranteed user-controlled accuracy”, Proceedings of the 11th IEEE International Conference on Data Mining, Pages 290-299, 2011.

Title: S-preconditioner for Multi-fold Data Reduction with Guaranteed User-controlled Accuracy

Abstract -The growing gap between the massive amounts of data generated by petascale scientific simulation codes and the capability of system hardware and software to effectively analyze this data necessitates data reduction. Yet, the increasing data complexity challenges most, if not all, of the existing data compression methods. In fact, lossless compression techniques offer no more than 10% reduction on scientific data that we have experience with, which is widely regarded as effectively incompressible. To bridge this gap, in this paper, we advocate a transformative strategy that enables fast, accurate, and multi-fold reduction of double-precision floating-point scientific data. The intuition behind our method is inspired by an effective use of preconditioners for linear algebra solvers optimized for a particular class of computational “dwarfs” (e.g., dense or sparse matrices). Focusing on a commonly used multi-resolution wavelet compression technique as the underlying “solver” for data reduction we propose the S?preconditioner, which transforms scientific data into a form with high global regularity to ensure a significant decrease in the number of wavelet coefficients stored for a segment of data. Combined with the subsequent EQ?calibrator, our resultant method (called S-Preconditioned EQ-Calibrated Wavelets (SPEQC–WAVELETS)), robustly achieved a 4- to 5-fold data reduction—while guaranteeing user-defined accuracy of reconstructed data to be within 1% point-by-point relative error, lower than 0.01 Normalized RMSE, and higher than 0.99 Pearson Correlation. In this paper, we show the results we obtained by testing our method on six petascale simulation codes including fusion, combustion, climate, astrophysics, and subsurface groundwater in addition to 13 publicly available scientific datasets. We also demonstrate that application-driven data mining tasks performed on decompressed variables or their derived quantities produce results of comparable quality with the ones for the original data.

Keywords: preconditioners for data mining; data reduction; data mining over decompressed data; in situ data analytics; extreme-scale data analytics


2. A. C. Bovik, "Automatic Prediction of Perceptual Image and Video Quality", Proceedings of the IEEE, Volume 101, Number 9, Pages 2008, 2024, September 2013.

Title: Automatic Prediction of Perceptual Image and Video Quality

Abstract: Finding ways to monitor and control the perceptual quality of digital visual media has become a pressing concern as the volume being transported and viewed continues to increase exponentially. This paper discusses the principles and methods of modern algorithms for automatically predicting the quality of visual signals. By casting the problem as analogous to assessing the efficacy of a visual communication system, it is possible to divide the quality assessment problem into understandable modeling sub problems. Along the way, we will visit models of natural images and videos, of visual perception, and a broad spectrum of applications.

Keywords: Digital photography; image quality; objective quality; video quality; visual perception; wireless spectrum crunch


3. A. Kolaman, and O. Yadid-Pecht, "Quaternion Structural Similarity: A New Quality Index for Color Images", IEEE Transactions on Image Processing, Volume 21, Number 4, Pages 1526, 1536, April 2012.

Title: Quaternion Structural Similarity: A New Quality Index for Color Images

Abstract: One of the most important issues for researchers developing image processing algorithms is image quality. Methodical quality evaluation, by showing images to several human observers, is slow, expensive, and highly subjective. On the other hand, a visual quality matrix (VQM) is a fast, cheap, and objective tool for evaluating image quality. Although most VQMs are good in predicting the quality of an image degraded by a single degradation, they poorly perform for a combination of two degradations. An example for such degradation is the color crosstalk (CTK) effect, which introduces blur with desaturation. CTK is expected to become a bigger issue in image quality as the industry moves toward smaller sensors. In this paper, we will develop a VQM that will be able to better evaluate the quality of an image degraded by a combined blur/desaturation degradation and perform as well as other VQMs on single degradations such as blur, compression, and noise. We show why standard scalar techniques are insufficient to measure a combined blur/desaturation degradation and explain why a vectorial approach is better suited. We introduce quaternion image processing (QIP), which is a true vectorial approach and has many uses in the fields of physics and engineering. Our new VQM
is a vectorial expansion of structure similarity using QIP, which gave it its name—Quaternion Structural SIMilarity (QSSIM).We built a new database of a combined blur/desaturation degradation and conducted a quality survey with human subjects. An extensive comparison between QSSIM and other VQMs on several image quality databases—including our new database—shows the superiority of this new approach in predicting visual quality of color images.

Keywords: Color image processing, hyper complex numbers, image quality index, quaternion image processing (QIP).

4. C. E. Rhee, K. Lee, T. S. Kim, and H.-J. Lee, "A survey of fast mode decision algorithms for inter-prediction and their applications to high efficiency video coding",  IEEE Transactions on Consumer Electronics, Volume 58, Number 4, Pages 1375, 1383, November 2012.

Title: A Survey of Fast Mode Decision Algorithms for Inter-Prediction and Their Applications to High Efficiency Video Coding

Abstract: The emerging High Efficiency Video Coding (HEVC) standard attempts to improve the coding efficiency by a factor of two over H.264/AVC using new compression tools with high computational complexity. The increased computational complexity makes the real-time execution with reasonable computing power become one of the critical concerns for the commercialization of HEVC. A large number of prediction modes are the main causes of the increased complexity of HEVC. Thus, a fast decision of a prediction mode needs to be effectively used to reduce the computational complexity. To take advantage of large amounts of previous works and to find a guide for application to HEVC, this paper presents a survey of these efforts for the previous standards, especially for H.264/AVC, and examines the possibility of the previous algorithms to be applicable for HEVC. To this end, previous algorithms are categorized and then the effectiveness of each category for HEVC is evaluated. For this evaluation, a previous algorithm is modified for HEVC when it is not applicable to HEVC directly. Simulation results show that most previous algorithms with slight modification, in general, improve the encoding speed with a relatively small degradation of the compression efficiency. Among them, hierarchical mode decision is especially effective whereas mode pre-decision using motion or spatial homogeneity often results in inaccurate results.

Keywords: Fast inter-prediction, Mode decision, Hardware encoder, HEVC, H.264/AVC

5. D. M. Chandler, and S. S. Hemami, "VSNR: A Wavelet-Based Visual Signal-to-Noise Ratio for Natural Images", IEEE Transactions on Image Processing, Volume 16, Number 9, Pages 2284, 2298, September 2007.

Title: VSNR: A Wavelet-Based Visual Signal-to-Noise Ratio for Natural Images

Abstract: This paper presents an efficient metric for quantifying the visual fidelity of natural images based on near-threshold and suprathreshold properties of human vision. The proposed metric, the visual signal-to-noise ratio (VSNR), operates via a two-stage approach. In the first stage, contrast thresholds for detection of distortions in the presence of natural images are computed via wavelet-based models of visual masking and visual summation in order to determine whether the distortions in the distorted image are visible. If the distortions are below the threshold of detection, the distorted image is deemed to be of perfect visual fidelity (VSNR = ?) and no further analysis is required. If the distortions are suprathreshold, a second stage is applied which operates based on the low-level visual property of perceived contrast, and the mid-level visual property of global precedence. These two properties are modeled as Euclidean distances in distortion-contrast space of a multiscale wavelet decomposition, and VSNR is computed based on a simple linear sum of these distances. The proposed VSNR metric is generally competitive with current metrics of visual fidelity; it is efficient both in terms of its low computational complexity and in terms of its low memory requirements; and it operates based on physical luminances and visual angle (rather than on digital pixel values and pixel-based dimensions) to accommodate different viewing conditions.

Keywords: Contrast, distortion, human visual system (HVS), image fidelity, image quality, noise, visual fidelity, wavelet.

6. H.-Y. Shum, S. B. Kang, and S.-C. Chan, "Survey of image-based representations and compression techniques", IEEE Transactions on Circuits and Systems for Video Technology, Volume 13, Number 11, Pages 1020,1037, Nov. 2003.

Title: Survey of Image-Based Representations and Compression Techniques

Abstract: In this paper, we survey the techniques for image-based rendering (IBR) and for compressing image-based representations. Unlike traditional three-dimensional (3-D) computer graphics, in which 3-D geometry of the scene is known, IBR techniques render novel views directly from input images. IBR techniques can be classified into three categories according to how much geometric information is used: rendering without geometry, rendering with implicit geometry (i.e., correspondence), and rendering with explicit geometry (either with approximate or accurate geometry). We discuss the characteristics of these categories and their representative techniques. IBR techniques demonstrate a surprising diverse range in their extent of use of images and geometry in representing 3-D scenes. We explore the issues in trading off the use of images and geometry by revisiting plenoptic-sampling analysis and the notions of view dependency and geometric proxies. Finally, we highlight compression techniques specifically designed for image-based representations. Such compression techniques are important in making IBR techniques practical.

Keywords: Image-based modeling, image-based rendering (IBR), image-based representations, survey.

7. M. Carnec, P. Le Callet, and D. Barba, "An image quality assessment method based on perception of structural information", Proceedings of the International Conference on Image Processing (ICIP), pages 185-8, September 2003.

Title: An Image Quality Assessment Method based on Perception of Structural Information

Abstract: This paper presents a new method to evaluate the quality of distorted images. This method is based on a comparison between the structural information extracted from the distorted image and from the original image. The interest of our method is that it uses reduced references containing perceptual structural information. First, a quick overview of image quality evaluation methods is given. Then the implementation of our Human Visual System (HVS) model is detailed. At last, results are given for quality evaluation of JPEG and JPEGZOM) coded images. They show that our method provides results which are highly correlated with human judgments (Mean Opinion Score). This method has been implemented in an application available on the Internet.

8. T. Ma, M. Hempel, D. Peng, and H. Sharif, "A survey of energy-efficient compression and communication techniques for multimedia in resource constrained systems", IEEE Communications Surveys and Tutorials, Volume 15, Number 3, Pages 963, 972, Third Quarter 2013.

Title: A Survey of Energy-Efficient Compression and Communication Techniques for Multimedia in Resource Constrained Systems

Abstract: Advances in wireless multimedia communication technologies enable new types of pervasive and ubiquitous applications such as mobile health care, environmental monitoring, and facility monitoring and traffic surveillance. Among different factors concerned, energy efficiency is one of the most challenging issues in multimedia communication due to the resource constraints, and the requirements for high bandwidth and low transmission delay. In this survey, we provide a broad picture of the state of-the-art energy efficient techniques that have been proposed in wireless multimedia communication for resource-constrained systems such as wireless sensor networks and mobile devices. Following the essential stages required for multimedia communication, we categorize these techniques into two groups: multimedia compression techniques and multimedia transmission techniques. In the first group, we introduce the state-of-the-art compression algorithms and perform analyses and evaluations on energy efficiency in applying these compression algorithms to resource-constrained multimedia transmission systems. In the second group, we will further categorize the energy efficient transmission techniques into two sub-categories according to their different communication architectures. We review both cross-layer communication, including Unequal Error Protection (UEP), and independent-layer communication, focusing on Routing, MAC, and Physical layer protocols. We present the basic problem statement and objectives of these techniques, and survey multiple potential approaches that have been reported in the literature. Our focus in this survey is to provide insight into different research directions to improve energy efficiency in wireless multimedia communication protocols for future developments.

Keywords: Survey, Energy Efficiency, Multimedia, Compression, Communication, Mobile, Resource Constrained, Cross-Layer
